{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from html_parser import load_df\n",
    "\n",
    "# Sample data\n",
    "texts = []  # Replace with your text data\n",
    "labels = []  # Replace with your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,l = load_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m[m['meta'] == 'message']\n",
    "m['content'] = m['content'].fillna('')\n",
    "texts = m['content'].tolist()\n",
    "labels = m['author'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jljew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.30      0.21      0.25      3202\n",
      "   Braden Brophy       0.00      0.00      0.00       136\n",
      "  Brittney Keene       0.00      0.00      0.00        32\n",
      "       Emma Kate       0.67      0.04      0.07       832\n",
      "     Emma Schuth       0.64      0.02      0.05      1003\n",
      "    Jason Jewell       0.36      0.10      0.16      2667\n",
      "   Jenna Jongsma       0.56      0.29      0.38      2142\n",
      "      Josie Diaz       0.00      0.00      0.00        43\n",
      " Mary Fitzgerald       0.27      0.72      0.40      3890\n",
      "  Matthew Eshaya       0.30      0.56      0.39      3805\n",
      "  Megan Giromini       0.83      0.01      0.02       477\n",
      "  Patric Bunhaus       0.00      0.00      0.00         1\n",
      "     Rhys Dudley       0.46      0.02      0.04      1264\n",
      "     Seren Adams       0.98      0.42      0.59       364\n",
      "Sophie Gillespie       0.46      0.04      0.08      1672\n",
      "      Will Black       0.00      0.00      0.00       213\n",
      "\n",
      "        accuracy                           0.31     21743\n",
      "       macro avg       0.37      0.15      0.15     21743\n",
      "    weighted avg       0.40      0.31      0.26     21743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jljew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jljew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# Create a pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.30      0.21      0.25      3202\n",
      "   Braden Brophy       1.00      0.00      0.00       136\n",
      "  Brittney Keene       1.00      0.00      0.00        32\n",
      "       Emma Kate       0.67      0.04      0.07       832\n",
      "     Emma Schuth       0.64      0.02      0.05      1003\n",
      "    Jason Jewell       0.36      0.10      0.16      2667\n",
      "   Jenna Jongsma       0.56      0.29      0.38      2142\n",
      "      Josie Diaz       1.00      0.00      0.00        43\n",
      " Mary Fitzgerald       0.27      0.72      0.40      3890\n",
      "  Matthew Eshaya       0.30      0.56      0.39      3805\n",
      "  Megan Giromini       0.83      0.01      0.02       477\n",
      "  Patric Bunhaus       1.00      0.00      0.00         1\n",
      "     Rhys Dudley       0.46      0.02      0.04      1264\n",
      "     Seren Adams       0.98      0.42      0.59       364\n",
      "Sophie Gillespie       0.46      0.04      0.08      1672\n",
      "      Will Black       1.00      0.00      0.00       213\n",
      "\n",
      "        accuracy                           0.31     21743\n",
      "       macro avg       0.68      0.15      0.15     21743\n",
      "    weighted avg       0.42      0.31      0.26     21743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta</th>\n",
       "      <th>author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>message</td>\n",
       "      <td>Annalise Panken</td>\n",
       "      <td>2020-01-30 07:55:00</td>\n",
       "      <td>Who is joe and why tf is he trading so damn much</td>\n",
       "      <td>46751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>message</td>\n",
       "      <td>Annalise Panken</td>\n",
       "      <td>2020-02-26 19:40:00</td>\n",
       "      <td>No</td>\n",
       "      <td>53972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>message</td>\n",
       "      <td>Annalise Panken</td>\n",
       "      <td>2021-02-18 07:25:00</td>\n",
       "      <td>Ok so APPARENTLY it’s not really my fault</td>\n",
       "      <td>115329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>message</td>\n",
       "      <td>Annalise Panken</td>\n",
       "      <td>2020-04-30 09:28:00</td>\n",
       "      <td>But she has 4 dogs and a cool husband</td>\n",
       "      <td>66977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>message</td>\n",
       "      <td>Annalise Panken</td>\n",
       "      <td>2019-12-15 10:20:00</td>\n",
       "      <td>I was mrs Potts</td>\n",
       "      <td>24665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>message</td>\n",
       "      <td>Will Black</td>\n",
       "      <td>2019-11-20 21:08:00</td>\n",
       "      <td>Oh..oh no</td>\n",
       "      <td>9946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>message</td>\n",
       "      <td>Will Black</td>\n",
       "      <td>2019-11-18 19:40:00</td>\n",
       "      <td>That was a time</td>\n",
       "      <td>6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>message</td>\n",
       "      <td>Will Black</td>\n",
       "      <td>2019-11-19 20:57:00</td>\n",
       "      <td>Which show?</td>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>message</td>\n",
       "      <td>Will Black</td>\n",
       "      <td>2019-11-18 19:10:00</td>\n",
       "      <td>Idk what you’re talking about</td>\n",
       "      <td>5928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>message</td>\n",
       "      <td>Will Black</td>\n",
       "      <td>2021-02-10 12:31:00</td>\n",
       "      <td>It’s weird being an adult now</td>\n",
       "      <td>114339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          meta  ... post_id\n",
       "0      message  ...   46751\n",
       "1      message  ...   53972\n",
       "2      message  ...  115329\n",
       "3      message  ...   66977\n",
       "4      message  ...   24665\n",
       "...        ...  ...     ...\n",
       "11995  message  ...    9946\n",
       "11996  message  ...    6196\n",
       "11997  message  ...    8578\n",
       "11998  message  ...    5928\n",
       "11999  message  ...  114339\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time, take 1000 random messages from each author that has sent at least 1000\n",
    "m = m[m['author'] != 'Josie Diaz']\n",
    "m = m[m['author'] != 'Brittney Keene']\n",
    "m = m[m['author'] != 'Memes of The Island']\n",
    "m = m[m['author'] != 'Patric Bunhaus']\n",
    "m = m[m['author'] != 'Braden Brophy']\n",
    "sampled = m.groupby('author').apply(lambda x: x.sample(n=1000)).reset_index(drop=True)\n",
    "sampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sampled['content'].tolist()\n",
    "labels = sampled['author'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.16      0.11      0.13       201\n",
      "       Emma Kate       0.37      0.18      0.25       195\n",
      "     Emma Schuth       0.32      0.13      0.18       214\n",
      "    Jason Jewell       0.15      0.14      0.15       197\n",
      "   Jenna Jongsma       0.33      0.23      0.27       200\n",
      " Mary Fitzgerald       0.21      0.37      0.27       202\n",
      "  Matthew Eshaya       0.15      0.10      0.12       206\n",
      "  Megan Giromini       0.29      0.26      0.27       196\n",
      "     Rhys Dudley       0.21      0.22      0.21       204\n",
      "     Seren Adams       0.79      0.49      0.60       212\n",
      "Sophie Gillespie       0.20      0.29      0.24       200\n",
      "      Will Black       0.17      0.44      0.25       173\n",
      "\n",
      "        accuracy                           0.24      2400\n",
      "       macro avg       0.28      0.25      0.24      2400\n",
      "    weighted avg       0.28      0.24      0.25      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# Create a pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try something else.\n",
    "texts = [''.join(e for e in string if e.isalnum() or e ==' ') for string in texts]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.19      0.16      0.17       201\n",
      "       Emma Kate       0.20      0.32      0.24       201\n",
      "     Emma Schuth       0.18      0.13      0.15       210\n",
      "    Jason Jewell       0.19      0.14      0.16       216\n",
      "   Jenna Jongsma       0.26      0.23      0.24       200\n",
      " Mary Fitzgerald       0.24      0.30      0.27       208\n",
      "  Matthew Eshaya       0.16      0.17      0.17       186\n",
      "  Megan Giromini       0.26      0.25      0.26       195\n",
      "     Rhys Dudley       0.19      0.22      0.20       187\n",
      "     Seren Adams       0.77      0.48      0.59       185\n",
      "Sophie Gillespie       0.26      0.20      0.23       222\n",
      "      Will Black       0.26      0.35      0.30       189\n",
      "\n",
      "        accuracy                           0.24      2400\n",
      "       macro avg       0.26      0.25      0.25      2400\n",
      "    weighted avg       0.26      0.24      0.25      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now let's try adding stylometric features. Exciting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Example function to extract stylometric features with standardized length\n",
    "def extract_features(text):\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "    \n",
    "    # Calculating features\n",
    "    avg_word_length = np.mean(word_lengths) if word_lengths else 0\n",
    "    avg_sentence_length = np.mean(sentence_lengths) if sentence_lengths else 0\n",
    "    punctuation_count = {punct: text.count(punct) for punct in string.punctuation}\n",
    "    capitalized_count = sum(1 for word in words if word.isupper())\n",
    "    \n",
    "    features = [avg_word_length, avg_sentence_length, capitalized_count] + list(punctuation_count.values())\n",
    "    return features\n",
    "\n",
    "# Apply to your dataset\n",
    "stylometric_features = [extract_features(text) for text in texts]\n",
    "\n",
    "# Convert stylometric features to a matrix\n",
    "X_stylometric = np.array(stylometric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Vectorize your text data (assuming you have already done this step)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Convert stylometric features to a matrix\n",
    "X_stylometric = np.array(stylometric_features)\n",
    "\n",
    "# Combine TF-IDF features with stylometric features\n",
    "\n",
    "\n",
    "# Assuming X_vectorized is a sparse matrix\n",
    "X_combined = hstack([X_vectorized, csr_matrix(X_stylometric)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jljew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.17      0.13      0.15       201\n",
      "       Emma Kate       0.21      0.40      0.27       201\n",
      "     Emma Schuth       0.22      0.15      0.18       210\n",
      "    Jason Jewell       0.18      0.29      0.22       216\n",
      "   Jenna Jongsma       0.30      0.37      0.33       200\n",
      " Mary Fitzgerald       0.21      0.28      0.24       208\n",
      "  Matthew Eshaya       0.29      0.19      0.23       186\n",
      "  Megan Giromini       0.26      0.21      0.23       195\n",
      "     Rhys Dudley       0.22      0.18      0.20       187\n",
      "     Seren Adams       0.80      0.54      0.64       185\n",
      "Sophie Gillespie       0.27      0.13      0.17       222\n",
      "      Will Black       0.29      0.26      0.27       189\n",
      "\n",
      "        accuracy                           0.26      2400\n",
      "       macro avg       0.28      0.26      0.26      2400\n",
      "    weighted avg       0.28      0.26      0.26      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to .26, that's nice (I guess?) Let's try an SVM now :)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.12      0.02      0.03       201\n",
      "       Emma Kate       0.13      0.11      0.12       201\n",
      "     Emma Schuth       0.20      0.02      0.04       210\n",
      "    Jason Jewell       0.15      0.11      0.12       216\n",
      "   Jenna Jongsma       0.15      0.12      0.13       200\n",
      " Mary Fitzgerald       0.25      0.07      0.11       208\n",
      "  Matthew Eshaya       0.10      0.82      0.17       186\n",
      "  Megan Giromini       0.12      0.03      0.05       195\n",
      "     Rhys Dudley       0.21      0.03      0.05       187\n",
      "     Seren Adams       0.87      0.47      0.61       185\n",
      "Sophie Gillespie       0.26      0.02      0.04       222\n",
      "      Will Black       0.10      0.02      0.03       189\n",
      "\n",
      "        accuracy                           0.15      2400\n",
      "       macro avg       0.22      0.15      0.13      2400\n",
      "    weighted avg       0.22      0.15      0.12      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the SVM classifier\n",
    "svm_model = SVC(kernel='poly')  # Linear: .27, rbf: .18, poly: .15\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)  # Assuming X_train is your feature set after combining TF-IDF and stylometric features\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = svm_model.predict(X_test)  # X_test is your test feature set\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  11.1s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  10.4s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=  19.7s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=  19.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.5s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  19.5s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  19.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  21.5s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  19.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   9.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   9.4s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=  55.6s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=  50.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.6s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=  54.1s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=  49.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.4s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=  53.3s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=  50.3s\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Annalise Panken       0.15      0.17      0.16       201\n",
      "       Emma Kate       0.22      0.33      0.26       201\n",
      "     Emma Schuth       0.20      0.17      0.19       210\n",
      "    Jason Jewell       0.20      0.21      0.20       216\n",
      "   Jenna Jongsma       0.40      0.36      0.38       200\n",
      " Mary Fitzgerald       0.26      0.26      0.26       208\n",
      "  Matthew Eshaya       0.22      0.30      0.25       186\n",
      "  Megan Giromini       0.27      0.24      0.26       195\n",
      "     Rhys Dudley       0.24      0.22      0.23       187\n",
      "     Seren Adams       0.84      0.56      0.67       185\n",
      "Sophie Gillespie       0.24      0.17      0.20       222\n",
      "      Will Black       0.27      0.29      0.28       189\n",
      "\n",
      "        accuracy                           0.27      2400\n",
      "       macro avg       0.29      0.27      0.28      2400\n",
      "    weighted avg       0.29      0.27      0.27      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 10],\n",
    "    'gamma': ['scale', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "best_predictions = best_svm_model.predict(X_test)\n",
    "print(classification_report(y_test, best_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
